# Autonomous Cleaning Robot with ROS 2

Este repositorio contiene el c√≥digo fuente de un **robot de limpieza aut√≥nomo** basado en ROS 2, implementado utilizando una **Raspberry Pi 4**, una **Kinect v1**, y una **Raspberry Pi Pico** con micro-ROS.

---

## Descripci√≥n General

El sistema est√° dividido en dos partes principales:

- **Raspberry Pi 4 (Unidad Principal):**
  - Conecta y gestiona la Kinect v1.
  - Ejecuta el agente de micro-ROS para comunicarse con la Pi Pico.
  - Publica datos de profundidad utilizados por `depthimage_to_laserscan`.
  - Lanza el mapeo SLAM con `slam_toolbox`.
  - Ejecuta la navegaci√≥n aut√≥noma con el nodo `wall_follower_node`.
  - Visualiza el robot y el entorno con RViz2 mediante un modelo URDF.

- **Raspberry Pi Pico (Unidad de Control):**
  - Se comunica con la Pi 4 v√≠a micro-ROS.
  - Se suscribe al t√≥pico `/cmd_vel` para controlar los motores.
  - Publica datos de encoders en el t√≥pico `/encoders`.

---

## Estructura del Proyecto

```bash
ros2_ws/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ pico_odometry/             # Nodo intermedio que convierte /encoders ‚Üí /odom
‚îÇ   ‚îú‚îÄ‚îÄ my_robot_description/      # URDF, meshes, view_robot.launch
‚îÇ   ‚îú‚îÄ‚îÄ wall_follower_slam/        # Nodo para navegaci√≥n autom√°tica por pared derecha
‚îÇ   ‚îú‚îÄ‚îÄ my_slam_launch/            # Launch que lanza SLAM + wall follower + RViz
‚îÇ   ‚îî‚îÄ‚îÄ kinect_ros2/               # Nodo modificado minimal_kinect_node.cpp
üîß Componentes Clave
minimal_kinect_node.cpp: nodo optimizado que publica solo los t√≥picos esenciales de profundidad (/depth/image_raw y /depth/camera_info) para reducir el uso de RAM.

depthimage_to_laserscan: transforma la imagen de profundidad en un LaserScan en /scan, utilizado para mapeo SLAM.

pico_odometry: nodo que convierte los datos crudos de encoders (/encoders) a odometr√≠a (/odom), ejecutado en la laptop.

slam_toolbox: herramienta utilizada para generar mapas en l√≠nea usando /scan y /odom.

wall_follower_node: permite al robot navegar de forma aut√≥noma siguiendo la pared derecha y explorando el entorno.

view_robot.launch.py: visualiza el modelo URDF del robot en RViz2.

C√≥mo Ejecutar
1. En la Raspberry Pi Pico
Sube el c√≥digo C de micro-ROS que publica /encoders y se suscribe a /cmd_vel.

2. En la Raspberry Pi 4
bash
Copy
Edit
# Ejecutar el agente de micro-ROS
ros2 run micro_ros_agent micro_ros_agent serial --dev /dev/ttyACM0

# Lanzar el nodo kinect m√≠nimo
ros2 run kinect_ros2 minimal_kinect_node

# Lanzar depthimage_to_laserscan
ros2 run depthimage_to_laserscan depthimage_to_laserscan_node
3. En la Laptop
bash
Copy
Edit
# Ejecutar nodo que convierte encoders a odometr√≠a
ros2 run pico_odometry encoder_to_odom_node

# Lanzar SLAM, navegaci√≥n autom√°tica y visualizaci√≥n
ros2 launch my_slam_launch slam_autonomous.launch.py
Dependencias
ROS 2 Jazzy

micro-ROS Agent

depthimage_to_laserscan

slam_toolbox

freenect (compilado desde fuente)

tf_transformations o transformations (Python)

rclcpp_components, image_transport, cv_bridge, camera_info_manager, sensor_msgs, etc.

Modelo URDF
El modelo del robot fue dise√±ado en SolidWorks y exportado a URDF. Se incluye en el paquete my_robot_description con archivos de malla y configuraciones para RViz2.

üó∫Ô∏è Estado del Proyecto
‚úÖ Publicaci√≥n de encoders
‚úÖ Conversi√≥n a odometr√≠a
‚úÖ Publicaci√≥n de /scan desde Kinect
‚úÖ Visualizaci√≥n en RViz
‚úÖ Mapeo SLAM en l√≠nea
‚úÖ Navegaci√≥n aut√≥noma por pared derecha
üî≤ Guardado y carga autom√°tica de mapas
üî≤ Planeamiento de rutas a puntos de inter√©s